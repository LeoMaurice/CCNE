---
title: "CCNE LDA"
author: "Léopold MAURICE, ENSAE"
date: "2023-12-21"
project: CCNE
supervision: Pr. Emmanuel Didier, CMH/ENS/EHESS
output-ext: html
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
    geometry:
      - top=10mm
      - left=20mm
      - right=20mm
      - bottom=10mm  
      - heightrounded
    highlight-style: github
    fontfamily: libertinus
    documentclass: report
    fig-width: 8
    fig-height: 8
  pdf:
    documentclass: report
    papersize: a4
    toc: true
    toc-depth: 4
    number-sections: true
    number-depth: 3
    colorlinks: true
    fig-width: 8
    fig-height: 8
    keep-tex: false
execute:
  eval: false
  message: false
  warning: false
  echo: false
  output: true
  error: true
editor: visual
biblatex bibliography: LDA_report.bib
---


```{r}
#| eval: true
#| setup: true

if (!require("pacman")) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse,
               lubridate,
               here,
               knitr,
               quanteda,
               quanteda.textstats,
               stm,
               topicmodels,
               LDAvis,
               ldatuning,
               readr,
               quanteda.textplots,
               ggprism,
               ggpmisc,
               RJSONIO,
               ggrepel,
               ggcorrplot,
               pdftools,
               #pdftk, pas dispo
               #tabulizer,
               tesseract,
               stringr,
               openxlsx,
               readxl,
               kableExtra
            )

# Some little helps from the internet
source("../src/helpers/lda_reports.R")
source("../src/helpers/database_creation.R")

seed = 1968
set.seed(seed)
```
# Introduction : base de données et pre-processing

## Présentation rapide de la base : les avis du CCNE

La base explorée est l'ensemble des 144 avis publiés par le Comité Consultatif National d'Ethique, depuis 1983 jusqu'à maintenant.

Le Comité Consultatif national d'Éthique, souvent abrégé CCNE, est une institution française indépendante créée en 1983. Son rôle central est d'apporter des réflexions éthiques sur les questions médicales, scientifiques et de santé publique. En tant qu'organe consultatif, le CCNE émet des avis sur des sujets variés tels que la bioéthique, la recherche médicale, les avancées technologiques dans le domaine de la santé, et d'autres enjeux éthiques contemporains. Composé de membres venant de la médecine clinique, de la recherche ou  des études théologiques, le CCNE favorise le dialogue entre experts de la médecine et de l'éthique et offre des recommandations visant à guider les décideurs publics.

Les avis sont extrêmement divers en terme de sujets (avec des récurrences comme la génétique, les cellules souches par exemple) ou de formats. Les premiers avis étaient plutôt courts, avec une partie recommendation de 2 pages et une annexe de quelques pages supplémentaires. Au cours du temps, la longueur des avis a largement augmenté comme montré sur la @fig-longueur. Les textes des avis sont récupérés depuis leur PDF disponible sur [le site du CCNE](https://www.ccne-ethique.fr/).

Notre base se compose aussi de quelques métadonnées sur les avis :
- date : date de publication du CCNE
- saisine : le CCNE peut être saisi par certaines institutions (président de la république, premier ministre, gouvernement, présidents du sénat et de l'assemblée), il doit alors rendre un avis. D'autres sujets sont décidés par les membres du CCNE selon leurs volontés ou les divers lettres qu'ils reçoivent.
- theme : le thème dans le quel l'administration du CCNE a rangé les avis.
- divergence : l'avis contient l'expression explicite d'une divergence
- president : Président du  CCNE au moment de la publication du CCNE
- composition du groupe de travail : les avis sont rédigés par deux rapporteurs (essentiellement), souvent accompagnés par d'autres membres intéressés par le sujet.

Une des hypothèses est que les présidents du CCNE ont une grande importance dans la rédaction des avis, et leurs rôles devraient pouvoir se retrouver dans les thèmes aborder par le CCNE.

```{r}
#| eval: true
rescrap_texte = FALSE

if(rescrap_texte){
  # Définir le chemin vers le dossier contenant les fichiers PDF
  dossier_avis <- "../data/raw/avis"
  
  # Liste des fichiers PDF dans le dossier
  liste_fichiers <- list.files(path = dossier_avis, pattern = "\\.pdf$", full.names = TRUE)
  
  # Initialiser un data.frame vide
  base_avis_ccne <- data.frame(num = integer(), avis = character(), 
                               nom_fichier = character(), nb_pages = integer(),
                               stringsAsFactors = FALSE)
  
  # Boucle pour lire chaque fichier PDF et extraire le texte
  for (fichier in liste_fichiers) {
    # Extraire le numéro du fichier
    numero <- as.integer(strsplit(strsplit(basename(fichier), " ")[[1]][2], ".pdf")[[1]])
    list_bugged <- c(69,70,71,72,76,77,78,79,80,83,84,86,89)
    if(numero %in% list_bugged){
      texte <- pdf_ocr_text(fichier) # embending de tesseract
    } else{
      texte <- pdf_text(fichier)
    }
    

    nombre_page <- pdf_info(fichier)$pages

    texte <- paste(texte, collapse = " ")
    
    # Ajouter les données au data.frame
    base_avis_ccne <- base_avis_ccne |>
      bind_rows(data.frame(num = numero, 
                           avis = texte,
                           nom_fichier = basename(fichier),
                           nb_pages = nombre_page,
                           stringsAsFactors = FALSE))
  }
  saveRDS(base_avis_ccne, "../data/intermediate/base_avis_ccne.rds")
} else {
  readRDS("../data/intermediate/base_avis_ccne.rds") -> base_avis_ccne
}

```

```{r}
#| eval: true

# base_avis_ccne <- read_delim("../data/exterior/base_avis_ccne_vf_1.tsv", 
#     delim = "\t", escape_double = FALSE, 
#     col_types = cols(Date = col_date(format = "%d/%m/%Y"), 
#         Date2 = col_date(format = "%Y-%m-%d")), 
#     trim_ws = TRUE)|>
#   select(Num_avis,
#          Date,
#          Titre,
#          txt_tot3,
#          Annee)|>
#   rename(num_avis=Num_avis,
#          avis = txt_tot3)

list_saisine_obligatoire <- c(
  "PR", #président
  "PM", #Premier Minsitre
  "MS", #ministère et secrétariat santé et autres appelations (solidarité, affaire social)
  "DGS", #direction générale de la santé
  "Parlement", #président d'AN et/ou sénat
  "Gouvernement", #autres membres du gouvernement
  "EP", #Etablissement public
  "EPES", #Etablissement public d'enseignement supérieur
  "CNRS",
  "INSERM",
  "IGAS", #inspection des affaires sociales = doute,
  "MILDT" # Mission Interministérielle de luttes contre la dépendance et la toxicomanie
)

base_avis_ccne |>
  left_join(read_excel("../data/raw/collected_metadata/metadata_avis.xlsx", 
            col_types = c("numeric", "date", "text", 
                "text", "text", "text", "logical", 
                "text", "text", "text", "date", "logical", 
                "text", "logical", "text"))|>
              mutate(saisine = saisine_precise %in% list_saisine_obligatoire,
                     date = as.Date(date)
                     )|>
              select(num,saisine,rapporteurs, membres_gt,titre_court,titre,date,theme,divergence))|>
  mutate(nb_mots = str_count(avis, "\\w+"),
         president = sapply(date, president_CCNE_by_date))-> base_avis_ccne

base_avis_ccne|>
  rename(Titre = titre,
         Date = date)|>
  mutate(Annee =year(Date),
         theme = as.factor(theme)) -> base_avis_ccne

base_avis_ccne$avis <- base_avis_ccne$avis|>
  str_replace_all("\\s+", " ") |>
  str_replace_all("[']", " ") |>
  str_replace_all("[’]", " ") |>
  str_replace_all("[`]", " ") |>
  str_replace_all("\r", " ") |>
  str_replace_all("\n", " ") |>
  str_replace_all("[,]",".") # pour certains chiffres

base_avis_ccne$Titre <- base_avis_ccne$Titre|>
  str_replace_all("\r", " ") |>
  str_replace_all("\n", " ")

# numbers and dates tokenisation

number_pattern <- "\\b\\d+\\b"

# Date pattern
date_pattern <- "\\b(?:\\d{4}-\\d{2}-\\d{2}|\\d{2}-\\d{2}-\\d{4}|\\d{4}-\\d{2}|\\d{2}-\\d{4}|\\d{2}-\\d{2})\\b"


# Replace numbers and dates with labels
 base_avis_ccne$avis <- base_avis_ccne$avis |>
   gsub(pattern = date_pattern, replacement = "date")
#   gsub(pattern = number_pattern, replacement = "number_token")

cp <- corpus(base_avis_ccne$avis, 
             docvars = base_avis_ccne |> select(num,
                                    avis, Titre, Annee, Date, saisine, divergence,president, theme) |> as.data.frame(), 
             docnames = base_avis_ccne$num)
# tokenisation
tk_original <- tokens(cp, remove_punct = TRUE, remove_numbers = TRUE)
```

```{r}
#| eval: true
#| label: fig-longueur
#| layout-ncol: 2
#| fig-cap-location: bottom
#| fig-cap: "Taille des avis au cours du temps"
#| fig-subcap: 
#|   - "Pages"
#|   - "Mots"
#| fig-env: "figure*"
#| fig-width: 8
#| fig-height: 5
ggplot(base_avis_ccne, aes(x = Date, y = nb_pages)) +
  geom_point() +  # Points pour chaque observation
  geom_smooth(formula = 'y ~ x', method = "loess", se = FALSE, color = "#077E97") +  # Lissage LOESS
  theme_prism() +  # Appliquer le thème ggprism
  labs(title = "Nombre de pages par avis en fonction du temps",
       x = "Date",
       y = "Nombre de pages")

ggplot(base_avis_ccne, aes(x = Date, y = nb_mots)) +
  geom_point() +  # Points pour chaque observation
  geom_smooth(formula = 'y ~ x', method = "loess", se = FALSE, color = "#C000C0") +  # Lissage LOESS
  theme_prism() +  # Appliquer le thème ggprism
  labs(title = "Nombre de mots par avis en fonction du temps",
       x = "Date",
       y = "Nombre de mots")
```
```{r}
#| eval: true
#| label: fig-avis_president
#| fig-cap-location: bottom
#| fig-cap: "Nombre d'avis par président"
#| fig-env: "figure*"

ggplot(base_avis_ccne, aes(x = president, fill = president)) +
  geom_bar() +
  scale_fill_prism(palette = "winter_bright") +  # Utiliser la palette winter_bright de ggprism
  theme_prism() +  # Appliquer le thème ggpubr
  labs(title = "Nombre d'avis par président du CCNE",
       x = "Président",
       y = "Nombre d'avis")+
  coord_flip()+
  theme(legend.position = "none")
```

```{r}
#| eval: true
#| label: fig-avis_president_theme
#| fig-cap-location: bottom
#| fig-cap: "Thème par président"
#| fig-env: "figure*"

ggplot(base_avis_ccne, aes(x = theme, fill = president)) +
  geom_bar() +
  scale_fill_prism(palette = "winter_bright") +  # Utiliser la palette winter_bright de ggprism
  theme_prism() +  # Appliquer le thème ggpubr
  labs(title = "Nombre d'avis par thème et président du CCNE",
       x = "Nombre d'avis par thème",
       y = "Président")+
  coord_flip()
    #theme(axis.text.x = element_text(angle = 90))  # Met les noms à 45°
```


## Preprocessing

### Contexte autour des mots

Pour pouvoir préparer correctement notre tokenisation, il nous faut regarder le contexte autour de certains mots. Deux exemples importants : le mot 'don' et le mot 'personne'. 

Le mot don est avant modification des tokens initiaux le mot le plus fréquent du corpus. Cependant, au regard des 2-grams le suivant présenté dans la @tbl-contexte_don, on peut voir que cela désigne plusieurs objets différents que nous avons rassemblés en quatre catégories : don de gamètes (d'ovocytes, de spermes etc.), don d'organe, don de sang, don de cellules. Ce découpage a fait perdre sa place au mot don.

Un découpage similaire a été opéré pour le mot 'personne' : on a distingué personne handicapée, personne handicapée mentale, personne malade, personne de confiance, personne agée, personne humaine potentielle (compromis désignant le foetus) en suivant les résultats de la @tbl-contexte_personne 

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'don'
#| label: tbl-contexte_don


kwic(tk_original, "don", window=2) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(20)|> 
  as.data.frame()|>
  rename(`Contexte après` = post, `Fréquence` = Freq) |>
  pivot_wider(names_from = `Contexte après`, values_from = `Fréquence`)|> 
  kable(booktabs = TRUE, longtable = TRUE, linesep = "", digits = 3)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'personne'
#| label: tbl-contexte_personne


kwic(tk_original, "personne", window=2) |> 
  as.data.frame() |>
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(20) |> 
  as.data.frame()|>
  rename(`Contexte après` = post, `Fréquence` = Freq) |>
  pivot_wider(names_from = `Contexte après`, values_from = `Fréquence`)|> 
  kable(booktabs = TRUE, longtable = TRUE, linesep = "", digits = 3)
```

```{r}
#| eval: false
#| output: true
#| tbl-cap: Examples de contexte précédant le mot 'personne'
#| label: tbl-contexte_pre_personne


kwic(tk_original, "personne", window=4) |> 
  as.data.frame() |> 
  select("pre") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: false
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'code'
#| label: tbl-contexte_code


kwic(tk_original, "code", window=4) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: false
#| output: true
#| fig-cap: Examples de contexte suivant les mots 'essai', 'expérience', 'expérimentation'
#| label: tbl-contexte_exp


kwic(tk_original, c("essai","expérience","expérimentation", "essais","expériences","expérimentations"), window=3) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(15)
```

```{r}
#| eval: false
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'droit'
#| label: tbl-contexte_droit_bis


kwic(tk_original, "droit", window=3) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(30)
```

### Tokenisation finale

En plus des séparations évoquées plus haut, dans le pré-traitement, on supprime les dates et nombres présents dans le texte et on regroupe sous un même dénomination plusieurs ensembles de mots. Par exemple, l'ensemble 'CCNE' ou 'comité national consultatif d'éthique' sont regroupés sous la même domination ou encore, 'avortement', 'ivg' et 'interruption volontaire de grosse' sont regroupés sous le même token d'avortement. On supprime aussi un certain nombre de mots dont la fréquence était élevé mais dont la pertinence semblait être faible ("peut", "comme" etc.). De plus, en regardant aussi les mots les plus fréquent on rassemble les pluriels ou les masculins/féminins de certains adjectifs comme humain/humaine/humains/humaines sous le même token. Pour finir, on supprime les mots dont il y a moins de 5 occurences dans tout le corpus.

```{r}
#| eval: true

# equivalence between differents words (or multiples words)
important_expressions <- dictionary(list(
    vntr = c("variable number of tandem repeat", "variable number tandem repeat"),
    ccne = c("comité national consultatif d éthique",
             "comité national d éthique",
             "comité consultatif d éthique",
             "comité d éthique",
             "comité consultatif national d ethique",
             "comité national consultatif d ethique",
             "comité national d ethique",
             "comité consultatif d ethique",
             "comité d ethique",
             "comité consultatif national d ethique",
             "comit é national consultatif d éthique",
             "comit é national d éthique",
             "comit é consultatif d éthique",
             "comit é d éthique",
             "comit é consultatif national d ethique",
             "comit é national consultatif d ethique",
             "comit é national d ethique",
             "comit é consultatif d ethique",
             "comit é consultatif national d ethique",
             "consultatif national d éthique",
             "Consultatif National d Éthique",
             "ce comité",
             "ccne",
             "ccné"),
    fin_de_vie = c("fin de vie", "fin de la vie"),
    personne_humaine_potentielle = c("personne humaine potentielles",
                                     "personnes humaines potentielles"),
    personne_agée = c("personne agée","personnes agées"),
    personne_handicapée_mentale = c("personne handicapée mentale",
                                    "personnes handicapées mentales",
                                    "personne atteinte d handicap mental",
                                    "personne atteinte d handicaps mentaux",
                                    "personnes atteintes d handicaps mentaux",
                                    "personnes atteintes d handicap mental",
                                    "personne atteinte de maladie mentale",
                                    "personne atteinte de maladies mentales",
                                    "personnes atteintes de maladie mentale",
                                    "personnes atteintes de maladies mentales"),
    personne_malade = c("personne malade",
                        "personnes malades",
                        "personne atteinte de maladie",
                        "personne atteinte de maladies",
                        "personnes atteintes de maladie",
                        "personnes atteintes de maladies"),
    personne_handicapée = c("personne handicapée",
                            "personnes handicapées",
                            "personne atteinte d handicap",
                            "personne atteinte d handicaps",
                            "personnes atteintes d handicaps",
                            "personnes atteintes d handicap"),
    personne_confiance = c("personne de confiance",
                           "personnes de confiance"),
    cellule_souche = c("cellule souche","cellules souches"),
    don_d_organe = c("don d organe","don d organes",
                     "dons d organe","dons d organes",
                     "don de moelle", "dons de moelle",
                     "don de moelles", "dons de moelles",
                     "don de tissu", "dons de tissu",
                     "don de tissus", "dons de tissus"),
    don_de_sang = c("don du sang","don de sang",
                    "dons du sang","dons de sang"),
    don_gamète = c("don d ovocyte", "don de gamète", "don d embryon",
                   "don d ovocytes", "don de gamètes", "don d embryons", 
                   "don de l embryon", "don de la gamète", "don de l ovocyte", 
                   "don de ces ovocytes", "don de ses ovocytes", "don de sperme", 
                   "don du sperme", "don de spermes",
                   "dons d ovocyte", "dons de gamète", "dons d embryon",
                   "dons d ovocytes", "dons de gamètes", "dons d embryons", 
                   "dons de l embryon", "dons de la gamète", "dons de l ovocyte", 
                   "dons de ces ovocytes", "dons de ses ovocytes", "dons de sperme", 
                   "dons du sperme", "dons de spermes"),
    don_cellule = c("don de cellule", "dons de cellule",
                    "don d'une cellule", "dons d'une cellule",
                    "don de cellules", "dons de cellules"),
    santé_publique = c("santé publique","santé pu- blique"),
    santé_travail = c("santé au travail", "santé du travail"),
    sécurité_sociale = c("sécurité sociale"),
    assurance_maladie = c("assurance_maladie"),
    ricoeur = c("ricoeur", "ricœur"),
    pma = c("amp","pma","PMA","AMP",
            "assistance médicale à la procréation",
            "assistances médicales à la procréation",
            "procréation médicalement assistée",
            "procréations médicalement assistées"),
    gpa = c("gpa",
            "gestation pour autrui"),
    vie_privée = c("vie privée",
                   "vies privées"),
    CRISPR_Cas9 = c("CRISPR-Cas9",
                    "crispr cas",
                    "crispr-cas",
                    "crispr-cas9",
                    "crispr cas9",
                    "crispr",
                    "CRISPR Cas9",
                    "CRISPR Cas",
                    "CRISPR-Cas",
                    "CRISPR",
                    "Cas9"),
    vih = c("vih","sida"),
    avortement = c("IVG","ivg",
                   "avortement",
                   "avortements",
                   "interruptions de grossesses",
                   "interruption de grossesse",
                   "interruption de grossesses",
                   "interruptions de grossesse"),
    fiv = c("fertilisation in vitro",
            "fiv",
            "fivete",
            "ivf",
            "ICSI",
            "injection intracytoplasmique de spermatozoïde",
            "intra cytoplasmic sperm injection",
            "intracytoplasmic sperm injection"),
    expérience = c("essai","expérience","expérimentation")
    
))

# suppression pluriel, genre

tk <- tokens_compound(tk_original, pattern = important_expressions, case_insensitive = TRUE)

replacement_dict <- dictionary(list(
  embryon = c("embryon*"),
  parent = c("parent*"),
  enfant = c("enfant*"),
  éthique = c("éthiques"),
  médical = c("médical*"),
  droit = c("droits"),
  don = c("dons"),
  gène = c("gènes"),
  femme = c("femmes"),
  malade = c("malades"),
  médecin = c("médecins"),
  patient = c("patients"),
  humain = c("humain*"), # risque de négliger les distinctions de genre ?
  personne = c("personnes","personne"),
  cellule = c("cellules"),
  test = c("tests"),
  génétique = c("génétiques"),
  problème = c("problèmes"),
  risque = c("risques"),
  question = c("questions"),
  résultat = c("résultats")
))

tk <- tokens_lookup(tk, replacement_dict, exclusive = FALSE)

# remove stop words
toremove <- c(stopwords("fr"), stopwords("en"),
              c("number_token", "number_token-number_token"),
              c("être", "a", "plus", "peut", "comme", 
              "d’une", "cas", "d’un", 
              "si", "entre", "fait", "non", "doit", 
              "dont", "aussi", 
              "ainsi", "tout", "faire", "donc", 
              "très", "°", "peuvent", "chez", 
              "bien", "où", "toute",
              "autres", "elles", 
              "moins", "in", "après", 
              "encore", "notamment", "certains", 
              "alors", "pourrait", "mise",
              "part", "autre","tous", "possible",
              "exemple", "n’est", "avoir", "souvent","of",">","<","+","u","NA"),
              c("qu’il", "avant", 
              "c’est", "certaines", 
              "selon", "celle", 
              "doivent", "déjà", 
              "celui", "lors", "plusieurs", 
              "sous", "toujours", 
              "depuis", "toutes", "concernant", 
              "devrait", "seulement",
              "faut", "telle",
              "également", "cependant", "façon", "fois",
              "prendre", "point", "nécessaire", 
              "p", "partir", "donner",
              "dès", "ni", "nouvelles",
              "aujourd","hui","agit",
              "objet","place","projet",
              "deux","ment","e",
              "méme","étre","etre","|","ȼ","Ȼ","¢" # ce symbole est utilisé en bio pour désigné cellule apparement.
              )
)
tk <- tokens_remove(tk,toremove)
# DFM format
dfm <- dfm(tk) |>
  dfm_lookup(important_expressions, exclusive = FALSE) |>
  dfm_remove(toremove) |>
  dfm_trim(min_termfreq = 5)

```

```{r}
topfeatures(dfm, 50, decreasing = TRUE) 
```


# Premières descriptions du corpus

On peut voir sur la @fig-wordcloud les mots les plus fréquents (au moins 750  dans le corpus) représenté sous la forme d'un wordcloud. On peut voir que malgré le fait d'avoir subdivisé grossièrement les sens de personne, le terme en lui-même reste le plus fréquent. Cela tend à confirmer le fait que le CCNE analyse les problématiques qui lui sont données au regard de la notion de personne en premier lieu. On retrouve aussi dans ce wordcloud des sujets essentiels comme le don de gamète, l'enfant, l'embryon, la génétique.

```{r}
#| eval: true
#| output: true
#| fig-cap: Mots les plus fréquents dans le corpus. La taille est proportionnelle à la fréquence.
#| label: fig-wordcloud
palette <-ggprism::prism_color_pal("winter_bright")(9)
textplot_wordcloud(dfm, min_count = 750, random_order = FALSE, rotation = 0.25,
                   color = palette)
```

```{r}
#| eval: true
#| output: true
#| fig-cap: Evolution des mots les plus fréquent du corpus au cours du temps
#| label: fig-word_time


important_words<- names(topfeatures(dfm,n=4))

dfm |>
  dfm_keep(pattern = important_words) |>
  textstat_frequency(groups = num) |>
  mutate(num = as.numeric((group)),
         feature = factor(feature, levels = important_words))|>
  left_join(base_avis_ccne, by = "num")|>
ggpubr::ggscatter(x="Date", y = "frequency", facet.by = "feature", xlab = "Temps",ylab = "Fréquence par avis",title = "Les mots les plus fréquents du corpus au cours du temps")+
    geom_smooth(formula = 'y ~ x', method = "loess", se = FALSE, color = "#C000C0") +  # Lissage LOESS
    theme_prism()
```

# Analyse : modélisation lexicométrique par Latent Dirichlet Allocation et Structural Topic Modelling

## Choix du nombre de topics

```{r}
#| eval: true
recompute_choix_K = FALSE
tm_data <- quanteda::convert(dfm, to = "topicmodels")
stm_data <- convert(dfm, to = "stm")


if(recompute_choix_K){
  list_nb_topics_K <- seq(5, 30)

  tp_nb <- FindTopicsNumber(tm_data, topics = list_nb_topics_K, 
                          metrics = c("Griffiths2004", "CaoJuan2009", 
                                      "Arun2010", "Deveaud2014"),
                          method = "Gibbs")

  diag <- searchK(stm_data$documents, stm_data$vocab, 
                  list_nb_topics_K, 
                  verbose=FALSE)
  save(tp_nb,list_nb_topics_K,diag, file = "../data/intermediate/report/LDA_report_metrics.RData")
} else{
  load("../data/intermediate/report/LDA_report_metrics.RData")
}

```

Pour choisir le nombre de topics de nos modèles, on regarde des métriques définies par de précédents auteurs (fonction `FindTopicsNumber` de `TopicModels`), présentées sur la @fig-lda-metrics. De plus, on compare pour chaque nombre de topics la cohérence sémantique et l'exclusivité (fonction `searchK` de `stm`), présenté dans la @fig-lda-exclu_cohsem. L'exclusivité mesure dans quel point un terme est associé de manière unique à un seul thème, tandis que la cohérence sémantique évalue le degré de similarité entre les termes au sein d'un thème, reflétant la cohésion interne et l'interprétabilité du thème. On voit que le dernier gros gain pour la métrique `Deveaud2014` se fait pour onze topics, c'est aussi vers ce nombre de topics que les autres courbes ont tendance à s'aplatir et donc qu'augmenter de un le nombre de topics ne donne pas beaucoup plus d'information tout en rendant plus complexe l'interprétation. On voit aussi qu'on gagne beaucoup en exclusivité (par rapport à la situation à 8 topics) quand on utilise 11 topics. Chaque topic devrait donc dépendre sur des mots spécifiques à chacun, même s'il faut renoncer à un peu de cohérence). Huit topics aurait pu être une bonne alternative.

```{r}
#| eval: true
#| output: true
#| fig-cap: Evolution de différentes métriques en fonction du nombre de topics
#| label: fig-lda-metrics

FindTopicsNumber_plot(tp_nb)+
  theme_prism()+
  scale_colour_prism("winter_bright")
  
```

```{r}
#| eval: true
#| output: true
#| fig-cap: Cohérence sémantique et excluvité en fonction du nombre de topics
#| label: fig-lda-exclu_cohsem
map(diag$results, unlist) |> 
  bind_cols() |> 
  ggplot(aes(exclus, semcoh, label = K, xlab = "Exclusivité", ylab = "Cohérence sémantique")) +
    geom_point() +
    geom_label() +
  theme_prism()
```

```{r}
#| eval: true
num_topic = 11
```

## STM à Onze topics

On réalise un structural topic modeling avec 11 topics et la formule suivante :
`prevalence =~ saisine + divergence + factor(president) + factor(theme) + s(Annee)`.

```{r}
#| eval: true

stm_data <- convert(dfm, to = "stm")

stm_lda <- stm(dfm,
               K=num_topic, 
               prevalence =~ saisine + divergence + factor(president) + factor(theme) + s(Annee),
               #content =~ saisine,
               init.type = "Spectral",
               seed = seed, 
               verbose = FALSE)
```

```{r}
#| eval: false
toLDAvis(stm_lda, stm_data$documents,reorder.topics = FALSE)

```

### Description des thèmes

A partir des mots les plus fréquents - présentés de façon courte dans la @fig-stm-summary_prob et de façon détaillée en annexe dans la @tbl-stm-full_prob_words - et des mots les plus exclusifs - de même, résumé figure @fig-stm-summary_frex, détails sur @tbl-stm-full_frex_words, on peut tenter de donner un premier sens à nos topics.

En les prenants dans l'ordre de prévalence :

- **Topic 3:** Correspond probablement au diagnostic génétique et prénatal.

- **Topic 2:** Peut correspondre aux questions de procréation et de risques pour l'enfant. L'autisme a malheureusement été traité dans ce sens dans un certain nombre d'avis.

- **Topic 9:** Correspond probablement aux réflexions éthiques portant sur la recherche clinique.

- **Topic 1:** Correspond aux questions relatives aux prélèvements de tissus humains.

- **Topic 6:** Correspond plus spécifiquement aux questions de recherche sur l'embryon, comme un sous-cas du topic 1. Il est important de rappeler que c'est l'un des thèmes.

- **Topic 10:** Difficile à distinguer du topic 9, plus d'explorations sont nécessaires. On peut penser qu'il est lié aux questions de greffes et de transplantations.

- **Topic 5:** Mélange entre les questions de drogue, de prix des médicaments et d'handicaps mentaux. Peut-être un lien commun par l'utilisation du vocabulaire de prix ou de travail.

- **Topic 8:** Semble être un topic sur l'éthique de façon plus générale, mais pas forcément sur la recherche clinique. Plutôt sur différents problèmes de santé publique : soins, COVID, vaccination, autotests comme le montre les plus exclusifs.

- **Topic 4:** Mélange l'euthanasie et la PMA. C'est possiblement lié à un vocabulaire commun autour de l'assistance, comme suggéré dans les tableaux détaillés.

- **Topic 7:** Correspond aux problématiques d'utilisation des données médicales avec le mot exclusif 'RGPD', par exemple.

```{r}
#| eval: true
#| output: true
#| echo: true
#| fig-cap: Les 3 mots les plus fréquents par topics. La ligne représente la prévalence dans le corpus du topic.
#| label: fig-stm-summary_prob
#| fig-width: 16

plot(stm_lda, type = "summary", labeltype = "prob")

```

```{r}
#| eval: true
#| output: true
#| echo: true
#| fig-cap: Les 3 mots les plus exclusifs (mesure FREX) par topics. La ligne représente la prévalence dans le corpus du topic.
#| label: fig-stm-summary_frex
#| fig-width: 16


plot(stm_lda, type = "summary", labeltype = "frex")

```
Pour aller plus en détails, on peut regarder les corrélations entre les topics, présentés dans la @fig-stm-corr_plot (et en annexe la matrice de corrélation complète, @fig-stm-corr_mat). On trouve que seuls les topic 1 et 6 sont très légèrements corrélés, car ils parlent tous les deux de prélévements chez l'humain. Les autres topics ne sont pas du tout corrélés entre eux ou voir légèrement négativement corrélés. Il semble que cela vient de l'initialisation par les valeurs spectrales.

```{r}
#| eval: true
#| output: true
#| echo: false
#| fig-cap: STM correlation between topics
#| label: fig-stm-corr_plot


corrmat <- topicCorr(stm_lda)
plot(corrmat)
```
Pour bien essayer de comprendre les différences entre les topic 9, 10 et 11, on peut les mettre en perspective.
On voit que le topic 9 par rapport au topic 10 est plus orienté recherche scientifique et éthique tandis que le topic 10 est plus orientés sur des techniques cliniques et médicales.
En faisant une comparaison similaire entre 9 et 11, on voit que les deux topics parlent d'éthique mais le 9 parle d'éthique de la recherche scientifique alors qu'on peut penser que le topic 11 se concentre sur des problématiques particulières (biodiversité, don de gamète, génétique). Dans cette comparaison, l'opposition entre les mots personnes et humains nous semblent vraiment intéressante : le traduit une intention pour le topic 11 surtout sur le corps biologique, tandis que le topic 9 parle de la personne, donc l'individu dans un sens plus général.
```{r}
#| eval: true
#| output: true
#| fig-cap: "Topic 9 contre Topic 10"
#| label: fig-stm-perspective910
#| fig-width: 16
#| fig-height: 8
plot(stm_lda, type = "perspectives", topics = c(9,10))
```

```{r}
#| eval: true
#| output: true
#| fig-cap: "Topic 9 contre Topic 11"
#| label: fig-stm-perspective911
#| fig-width: 16
#| fig-height: 8
plot(stm_lda, type = "perspectives", topics = c(9,11))
```

```{r}
findTopic(stm_lda, c("humain"))
```
Pour terminer sur la description des topics, on peut regarder pour chaque topic, quels avis montrent la plus forte prévalence de topic. On montre dans la @tbl-stm-top_avis.
Cela permet de nuancer l'imprétation des topics. On peut ainsi dire que : 

- **Topic 1:** Utilisation de produits issus du corps humain.

- **Topic 10:** Utilisation de parties du corps humain, incluant la greffe et un avis sur l'exposition des corps au musée, soulevé par une lettre du Museum d'histoire naturelle.

- **Topic 11:** Semble recouper plusieurs sujets différents. Peut être interprété comme la montée de l'importance de regarder en écosystème les questions de santé, y compris la biodiversité et la manipulation du génome.

- **Topic 2:** Correspond à la sexualité, la reproduction et les risques, avec des avis sur la contraception et l'enjeu du don du sang pour les hommes ayant des rapports avec d'autres hommes.

- **Topic 3:** Correspond bien au diagnostic prénatal et génétique.

- **Topic 4:** Semble correspondre à la fin de vie, en incluant la santé en prison, en raison d'un grand volet sur la fin de vie en prison dans l'avis n°94.

- **Topic 5:** Correspond à l'usage des drogues et aux risques de certains traitements médicamenteux (centoxin, anti-corps autorisé en 1991, puis retiré en 1993 en raison de falsifications). Interprétable comme substances et risques.

- **Topic 6:** Correspond au thème de l'embryon.

- **Topic 7:** Thème des données de santé.

- **Topic 8:** Éthique en situation de santé publique, incluant les pandémies, les vaccinations et la santé des migrants.

- **Topic 9:** Éthique et recherche, notamment l'étonnant avis n°131 dédié aux expérimentations en sciences de l'éducation, sciences cognitives et psychologie, expliquant la prévalence du terme "pédagogie".

```{r}
#| eval: true
#| output: true
#| tbl-cap: "Top 3 des avis avec le plus grande prévalence par topic"
#| tbl-cap-location: bottom
#| label: tbl-stm-top_avis
make.dt(stm_lda,meta = stm_data$meta)|> 
  select(num,Titre, starts_with("Topic"),Date, president) |>
  pivot_longer(starts_with("Topic"))|>
  group_by(name)|>
  rename(`N°avis` = num, Topic = name, Prevalence = value,President = president)|>
  slice_max(order_by = Prevalence, n = 3) |>  # Sélectionne les 2 premiers pour chaque name
  kable(digits = 3)
```

On obtient finalement les interprésentations grossières présentés dans @tbl-stm-interpretations.

```{r}
#| eval: true
#| tbl-cap: "Interprétations de nos topics"
#| label: tbl-stm-interpretations
#| tbl-colwidths: [10,90]
#| fig-width: 16
#| fig-height: 16
interpretations <- c(
  "1 Produits corpus humains",
  "2 Rapports sexuels et risques",
  "3 Diagnostic génétique",
  "4 Fin de vie et assistance",
  "5 Substances et risques",
  "6 Embryon",
  "7 Données",
  "8 Santé publique",
  "9 Recherche",
  "10 Corps",
  "11 Ecosystèmes"
)

topic_names <- setNames(interpretations, paste0("Topic", 1:length(interpretations)))
# Ajuster les options pour afficher toutes les lignes
options("dplyr.print_max" = Inf)

data.frame(
  num = as.integer(gsub("[^0-9]", "", names(topic_names))),  # Extraire les numéros d'avis
  Interprétation = gsub("^\\d+\\s", "", interpretations)  # Utiliser les interprétations
)|> 
rename("N° Avis"=num)|>
kable(digits = 3)


```


### Effets des métadonnées sur la prévalence

Grâce à notre modélisation par un structural topic modelling, on peut regarder l'effet de nos métadata sur la prévalence des thèmes. Globalement dans les tableaux présentés @tbl-stm-main_effects, il y a une certaines cohérences entre notre interprétation et l'effet des covariables:

* **Topic 1:** Utilisation du corps humain
  - Croît avec la thématique greffe, ce qui est logique vu qu'il semble parler d'utiliser les tissus humains.
  - Intéressant de noter que c'est un sujet qui décroît avec tous les présidents depuis 1992.

* **Topic 2:** Effets positifs et significatifs
  - Respectivement à 1% et à 10% pour les thèmes sexualité, genre, et du thème procréation.
  - Logique pour le topic associé aux risques de ces pratiques (?).

* **Topic 3:** Topic extrêmement transversal aux questionnements du CCNE.

* **Topic 4:** Effet très très fortement significatif du thème fin de vie, confirmant notre interprétation.

* **Topics 5, 6, et 11:** Effets et interprétations complexes à mettre en lien.

* **Topics 7 et 8:** Influence des questions de santé publique, logique avec nos interprétations.

* **Topic 9:** Significativité des politiques de santé et de la recherche.

* **Topic 10:** Influence du corps (thème des greffes), mais surtout l'importance du droit.

Pour l'interprétation des autres covariables, on peut noter quelques points intéressants. L'actuel président (depuis 2016) Jean-François Delfraissy semble marquer quelques ruptures : il a un effet positif et significatif sur les topics 7, 8, et 11 qui marquent un tournant vers la santé publique et les écosystèmes et non plus simplement une éthique de la pratique clinique. Cela semble aller dans le sens que le CCNE s'est ouvert à insérer sa réflexion dans la société et la nature.

Une autre rupture notable est le topic 11 où tous les présidents du CCNE depuis 1992 ont un effet négatif (et significatif à 5%) sur sa prévalence. Mais cela semble difficile de le faire correspondre avec un événement historique ou un changement structurel du CCNE. De même pour le topic 5 concernant les risques des médicaments qui semblent avoir été sous évoqué durant la présidence de Jean Claude Aimensen de 2012 à 2015.

L'essentiel des autres topics sont guidés principalement par leurs sujets et thèmes ce qui laisse à penser une cohérence de vocabulaire et lexicographique au cours du temps. 

Dernière remarque, contrairement à ce qu'on pourrait penser, il n'y a peu d'effet sur les thèmes abordés du fait d'avoir été saisi par une institution officielle. La demande politique semble faire baisser (de façon significatif à 10%) la prévalence du topic 2 "sexualité et risque" et du topic 10 "corps". Si dans le second cas, cela semble relativement logique car ce sont des préocupations de terrains (de chirurgiens ou de musées), le premier cas semble d'intérêt publique surtout avec la crise du SIDA. Une explication possible pour ce résultat étonnant est que la crise du VIH fait l'objet de ses propres négociations et réflexions en dehors du CCNE.

```{r}
#| eval: true
stm_lda.effect <- estimateEffect(formula = 1:num_topic ~ saisine + divergence + factor(president) + factor(theme), stmobj = stm_lda, metadata = stm_data$meta, uncertainty="Global")
```

```{r}
#| eval: true
#| output: true
#| label: tbl-stm-main_effects
#| tbl-cap: "Effets significatifs des métadonnées sur les différents topics"
# tbl-cap-location: top
#| tbl-colwidths: [100]
data.frame()|>kable()
```

```{r}
#| eval: true
#| output: true
#| results: asis
summary(stm_lda.effect) -> summary_stm_main_effects
signif_code_footnotes = "Signif. codes, p<t : 0.001 ‘\u00B7\u00B7\u00B7\u00B7’ 0.01 ‘\u00B7\u00B7\u00B7’ 0.05 ‘\u00B7\u00B7’ 0.1 ‘\u00B7’ "

signif_codes <- function(p){
  if(p<=0.001)
    return("\u2022\u2022\u2022\u2022")
  else if(p < 0.01)
    return("\u2022\u2022\u2022")
  else if(p <0.5)
    return("\u2022\u2022")
  else if(p<0.1)
    return("\u2022")
  else
    return("")
}

# data.frame()|>
#   kable(caption = "**Effets significatifs des métadonnées sur les différents topics**",
#         label = "tbl-stm-main_effects")


for(i in 1:num_topic){
  # if (i==1)
  #   topic_label = "tbl-stm-main_effects"
  # else
  topic_label = paste("tbl-stm-main_effects",i,collapse = "-")
  topic_caption <- paste("Effets structurels significatifs sur la prévalence des thèmes pour le topic",
                         topic_names[paste0("Topic",i)], collaspe = "\n")
  cat(summary_stm_main_effects$tables[[i]] |>
    as.data.frame()|>
    mutate(signif = sapply(`Pr(>|t|)`,signif_codes))|>
    filter(`Pr(>|t|)`<=0.1)|>
      kable(caption = topic_caption, digits = 3,
            label = topic_label)|>
      footnote(signif_code_footnotes))
  cat("\n\n")
}

```

```{r}
# plot(stm_lda.effect, type = "perspectives", topics = c(10), covariate = "saisine", xlab = "Saisine", model = stm_lda.effect, method = "pointestimate")
```

```{r}
#| eval: true
#| output: true
#| fig-cap: Prevalence des topics au cours du temps dans les documents (présentant une prévalence d'au moins 0.1)
#| label: fig-stm-time

make.dt(stm_lda,meta = stm_data$meta)|> select(num,Date, starts_with("Topic")) |>
  pivot_longer(starts_with("Topic")) |>
  filter(value >0.1)|>
  mutate(name = topic_names[name])|> 
  ggpubr::ggscatter(x="Date", y = "value", 
                    facet.by = "name",
                    xlab = "Temps",ylab = "Prevalence", title = "Prevalence of each topics by documents overtime")+
  geom_smooth(formula = 'y ~ x', method = "loess", se = FALSE, color = "#C000C0")+
  theme_prism()
```

# Annexe

## STM à 11 topics

### Labelisation des topics

```{r}
#| eval: true
#| output: true
#| label: tbl-stm-full_prob_words
# tab-cap: "Ensemble des 15 mots les plus fréquents par topic"
# tbl-cap-location: top


plot(stm_lda, type = "labels", labeltype = "prob", n=12)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: "Ensemble des 15 mots les plus exclusifs par topic"
#| label: tbl-stm-full_frex_words
# tbl-cap-location: top

plot(stm_lda, type = "labels", labeltype = "frex", frexw=0.5, n = 12)
```

```{r}
#| eval: false
#| output: false
#| echo: false
#| fig-cap: "Ensemble des mots par topic pour toutes les mesures disponibles"
#| label: fig-stm-full_all_measures_word

labelTopics(stm_lda)

```
### Liens entre les topics

```{r}
#| eval: True
#| output: True
#| echo: false
#| fig-cap: "Matrice de corrélation entre les topics"
#| label: fig-stm-corr_mat
ggcorrplot(corrmat$cor)
```

```{r}
plot(stm_lda, type = "hist")
```

### Tables complètes des effets structurelles

```{r}
#| eval: true
#| output: true
#| label: tbl-stm-full_reg_tab
#| results: asis
#| tbl-cap: "Effets des métadonnées sur les différents topics"

summary(estimateEffect(formula = 1:num_topic ~ saisine + divergence + factor(president) + factor(theme) + s(Annee), stmobj = stm_lda, metadata = stm_data$meta, uncertainty="Global")) -> complete_estimation_effects 

for(i in 1:num_topic){
  topic_caption <- paste("Effets structurels sur la prévalence des thèmes pour le topic", i,
                         topic_names[paste0("Topic",i)])
  cat(complete_estimation_effects$tables[[i]] |>
    as.data.frame()|>
    mutate(signif = sapply(`Pr(>|t|)`,signif_codes))|>
      kable(caption = topic_caption, digits = 3)|>
      footnote(signif_code_footnotes))
  cat("\n\n")
}
```

