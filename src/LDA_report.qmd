---
title: "CCNE LDA"
author: "Léopold MAURICE, ENSAE"
date: "2023-07-11"
project: CCNE
supervision: Pr. Emmanuel Didier, CMH/ENS/EHESS
output-ext: html
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
    geometry:
      - top=10mm
      - left=20mm
      - right=20mm
      - bottom=10mm  
      - heightrounded
    highlight-style: github
    fontfamily: libertinus
    documentclass: report
    fig-width: 8
    fig-height: 8
  pdf:
    documentclass: report
    papersize: a4
    toc: true
    toc-depth: 4
    number-sections: true
    number-depth: 3
    colorlinks: true
    fig-width: 8
    fig-height: 8
    keep-tex: false
execute:
  eval: false
  message: false
  warning: false
  echo: false
  output: true
  error: true
editor: visual
---

citation_package: biblatex bibliography: references.bib

# Set up

```{r}
#| eval: true

if (!require("pacman")) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse,
               lubridate,
               here,
               knitr,
               quanteda,
               quanteda.textstats,
               stm,
               topicmodels,
               LDAvis,
               ldatuning,
               readr,
               quanteda.textplots,
               ggprism,
               ggpmisc,
               RJSONIO,
               ggrepel,
               ggcorrplot,
               pdftools,
               #pdftk, pas dispo
               #tabulizer,
               tesseract,
               stringr,
               openxlsx,
               readxl
            )

# Some little helps from the internet
source("../src/helpers/lda_reports.R")

seed = 1968
set.seed(seed)
```
# Pre-processing

## Premiers prétraitements

Extraction des textes des avis

```{r}
rescrap_texte = FALSE

if(rescrap_texte){
  # Définir le chemin vers le dossier contenant les fichiers PDF
  dossier_avis <- "../data/raw/avis"
  
  # Liste des fichiers PDF dans le dossier
  liste_fichiers <- list.files(path = dossier_avis, pattern = "\\.pdf$", full.names = TRUE)
  
  # Initialiser un data.frame vide
  base_avis_ccne <- data.frame(num = integer(), avis = character(), 
                               nom_fichier = character(), nb_pages = integer(),
                               stringsAsFactors = FALSE)
  
  # Boucle pour lire chaque fichier PDF et extraire le texte
  for (fichier in liste_fichiers) {
    # Extraire le numéro du fichier
    numero <- as.integer(strsplit(strsplit(basename(fichier), " ")[[1]][2], ".pdf")[[1]])
    list_bugged <- c(69,70,71,72,76,77,78,79,80,83,84,86,89)
    if(numero %in% list_bugged){
      texte <- pdf_ocr_text(fichier)
    } else{
      texte <- pdf_text(fichier)
    }
    

    nombre_page <- pdf_info(fichier)$pages

    texte <- paste(texte, collapse = " ")
    
    # Ajouter les données au data.frame
    base_avis_ccne <- base_avis_ccne |>
      bind_rows(data.frame(num = numero, 
                           avis = texte,
                           nom_fichier = basename(fichier),
                           nb_pages = nombre_page,
                           stringsAsFactors = FALSE))
  }
  saveRDS(base_avis_ccne, "../data/intermediate/base_avis_ccne.rds")
} else {
  readRDS("../data/intermediate/base_avis_ccne.rds") -> base_avis_ccne
}

```


```{r}
#| eval: true

# base_avis_ccne <- read_delim("../data/exterior/base_avis_ccne_vf_1.tsv", 
#     delim = "\t", escape_double = FALSE, 
#     col_types = cols(Date = col_date(format = "%d/%m/%Y"), 
#         Date2 = col_date(format = "%Y-%m-%d")), 
#     trim_ws = TRUE)|>
#   select(Num_avis,
#          Date,
#          Titre,
#          txt_tot3,
#          Annee)|>
#   rename(num_avis=Num_avis,
#          avis = txt_tot3)

list_saisine_obligatoire <- c(
  "PR", #président
  "PM", #Premier Minsitre
  "MS", #ministère et secrétariat santé et autres appelations (solidarité, affaire social)
  "DGS", #direction générale de la santé
  "Parlement", #président d'AN et/ou sénat
  "Gouvernement", #autres membres du gouvernement
  "EP", #Etablissement public
  "EPES", #Etablissement public d'enseignement supérieur
  "CNRS",
  "INSERM",
  "IGAS", #inspection des affaires sociales = doute,
  "MILDT"
)

base_avis_ccne |>
  left_join(read_excel("../data/raw/collected_metadata/metadata_avis.xlsx", 
            col_types = c("numeric", "date", "text", 
                "text", "text", "text", "logical", 
                "text", "text", "text", "date", "logical", 
                "text", "logical", "text"))|>
              mutate(saisine = saisine_precise %in% list_saisine_obligatoire)|>
              select(num,saisine,rapporteurs, membres_gt,titre_court,titre,date,theme,divergence)) -> base_avis_ccne

base_avis_ccne|>
  rename(Titre = titre,
         Date = date)|>
  mutate(Annee =year(Date)) -> base_avis_ccne

base_avis_ccne$avis <- base_avis_ccne$avis|>
  str_replace_all("\\s+", " ") |>
  str_replace_all("[']", " ") |>
  str_replace_all("[’]", " ") |>
  str_replace_all("[`]", " ") |>
  str_replace_all("\r", " ") |>
  str_replace_all("\n", " ") |>
  str_replace_all("[,]",".") # pour certains chiffres

base_avis_ccne$Titre <- base_avis_ccne$Titre|>
  str_replace_all("\r", " ") |>
  str_replace_all("\n", " ")

# numbers and dates tokenisation

number_pattern <- "\\b\\d+\\b"

# Date pattern
date_pattern <- "\\b(?:\\d{4}-\\d{2}-\\d{2}|\\d{2}-\\d{2}-\\d{4}|\\d{4}-\\d{2}|\\d{2}-\\d{4}|\\d{2}-\\d{2})\\b"


# Replace numbers and dates with labels
 base_avis_ccne$avis <- base_avis_ccne$avis |>
   gsub(pattern = date_pattern, replacement = "date")
#   gsub(pattern = number_pattern, replacement = "number_token")

cp <- corpus(base_avis_ccne$avis, 
             docvars = base_avis_ccne |> select(num,
                                    avis, Titre, Annee, Date, saisine, divergence, theme) |> as.data.frame(), 
             docnames = base_avis_ccne$num)
# tokenisation
tk_original <- tokens(cp, remove_punct = TRUE, remove_numbers = TRUE)
```
## Contexte autour des mots

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot don
#| label: tbl-contexte_don


kwic(tk_original, "don", window=2) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(15)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'personne'
#| label: tbl-contexte_personne


kwic(tk_original, "personne", window=2) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte précédant le mot 'personne'
#| label: tbl-contexte_pre_personne


kwic(tk_original, "personne", window=4) |> 
  as.data.frame() |> 
  select("pre") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: false
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'code'
#| label: tbl-contexte_code


kwic(tk_original, "code", window=4) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: false
#| output: true
#| fig-cap: Examples de contexte suivant les mots 'essai', 'expérience', 'expérimentation'
#| label: tbl-contexte_exp


kwic(tk_original, c("essai","expérience","expérimentation", "essais","expériences","expérimentations"), window=3) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(15)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'droit'
#| label: tbl-contexte_droit_bis


kwic(tk_original, "droit", window=3) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(30)
```

## Création DFM

```{r}
#| eval: true

# equivalence between differents words (or multiples words)
important_expressions <- dictionary(list(
    vntr = c("variable number of tandem repeat", "variable number tandem repeat"),
    ccne = c("comité national consultatif d éthique",
             "comité national d éthique",
             "comité consultatif d éthique",
             "comité d éthique",
             "comité consultatif national d ethique",
             "comité national consultatif d ethique",
             "comité national d ethique",
             "comité consultatif d ethique",
             "comité d ethique",
             "comité consultatif national d ethique",
             "comit é national consultatif d éthique",
             "comit é national d éthique",
             "comit é consultatif d éthique",
             "comit é d éthique",
             "comit é consultatif national d ethique",
             "comit é national consultatif d ethique",
             "comit é national d ethique",
             "comit é consultatif d ethique",
             "comit é consultatif national d ethique",
             "consultatif national d éthique",
             "Consultatif National d Éthique",
             "ce comité",
             "ccne",
             "ccné"),
    fin_de_vie = c("fin de vie", "fin de la vie"),
    personne_humaine_potentielle = c("personne humaine potentielles",
                                     "personnes humaines potentielles"),
    personne_agée = c("personne agée","personnes agées"),
    personne_handicapée_mentale = c("personne handicapée mentale",
                                    "personnes handicapées mentales",
                                    "personne atteinte d handicap mental",
                                    "personne atteinte d handicaps mentaux",
                                    "personnes atteintes d handicaps mentaux",
                                    "personnes atteintes d handicap mental",
                                    "personne atteinte de maladie mentale",
                                    "personne atteinte de maladies mentales",
                                    "personnes atteintes de maladie mentale",
                                    "personnes atteintes de maladies mentales"),
    personne_malade = c("personne malade",
                        "personnes malades",
                        "personne atteinte de maladie",
                        "personne atteinte de maladies",
                        "personnes atteintes de maladie",
                        "personnes atteintes de maladies"),
    personne_handicapée = c("personne handicapée",
                            "personnes handicapées",
                            "personne atteinte d handicap",
                            "personne atteinte d handicaps",
                            "personnes atteintes d handicaps",
                            "personnes atteintes d handicap"),
    personne_confiance = c("personne de confiance",
                           "personnes de confiance"),
    cellule_souche = c("cellule souche","cellules souches"),
    don_d_organe = c("don d organe","don d organes",
                     "dons d organe","dons d organes",
                     "don de moelle", "dons de moelle",
                     "don de moelles", "dons de moelles",
                     "don de tissu", "dons de tissu",
                     "don de tissus", "dons de tissus"),
    don_de_sang = c("don du sang","don de sang",
                    "dons du sang","dons de sang"),
    don_gamète = c("don d ovocyte", "don de gamète", "don d embryon",
                   "don d ovocytes", "don de gamètes", "don d embryons", 
                   "don de l embryon", "don de la gamète", "don de l ovocyte", 
                   "don de ces ovocytes", "don de ses ovocytes", "don de sperme", 
                   "don du sperme", "don de spermes",
                   "dons d ovocyte", "dons de gamète", "dons d embryon",
                   "dons d ovocytes", "dons de gamètes", "dons d embryons", 
                   "dons de l embryon", "dons de la gamète", "dons de l ovocyte", 
                   "dons de ces ovocytes", "dons de ses ovocytes", "dons de sperme", 
                   "dons du sperme", "dons de spermes"),
    don_cellule = c("don de cellule", "dons de cellule",
                    "don d'une cellule", "dons d'une cellule",
                    "don de cellules", "dons de cellules"),
    santé_publique = c("santé publique"),
    sécurité_sociale = c("sécurité sociale"),
    assurance_maladie = c("assurance_maladie"),
    ricoeur = c("ricoeur", "ricœur"),
    pma = c("amp","pma","PMA","AMP",
            "assistance médicale à la procréation",
            "assistances médicales à la procréation",
            "procréation médicalement assistée",
            "procréations médicalement assistées"),
    gpa = c("gpa",
            "gestation pour autrui"),
    vie_privée = c("vie privée",
                   "vies privées"),
    CRISPR_Cas9 = c("CRISPR-Cas9",
                    "crispr cas",
                    "crispr-cas",
                    "crispr-cas9",
                    "crispr cas9",
                    "crispr",
                    "CRISPR Cas9",
                    "CRISPR Cas",
                    "CRISPR-Cas",
                    "CRISPR",
                    "Cas9"),
    vih = c("vih","sida"),
    avortement = c("IVG","ivg",
                   "avortement",
                   "avortements",
                   "interruptions de grossesses",
                   "interruption de grossesse",
                   "interruption de grossesses",
                   "interruptions de grossesse"),
    fiv = c("fertilisation in vitro",
            "fiv",
            "fivete",
            "ivf",
            "ICSI",
            "injection intracytoplasmique de spermatozoïde",
            "intra cytoplasmic sperm injection",
            "intracytoplasmic sperm injection"),
    expérience = c("essai","expérience","expérimentation")
    
))

# suppression pluriel, genre

tk <- tokens_compound(tk_original, pattern = important_expressions, case_insensitive = TRUE)

replacement_dict <- dictionary(list(
  embryon = c("embryon*"),
  parent = c("parent*"),
  enfant = c("enfant*"),
  éthique = c("éthiques"),
  médical = c("médical*"),
  droit = c("droits"),
  don = c("dons"),
  gène = c("gènes"),
  femme = c("femmes"),
  malade = c("malades"),
  médecin = c("médecins"),
  patient = c("patients"),
  humain = c("humain*"), # risque de négliger les distinctions de genre ?
  personne = c("personnes","personne"),
  cellule = c("cellules"),
  test = c("tests"),
  génétique = c("génétiques"),
  problème = c("problèmes"),
  risque = c("risques"),
  question = c("questions"),
  résultat = c("résultats")
))

tk <- tokens_lookup(tk, replacement_dict, exclusive = FALSE)

# remove stop words
toremove <- c(stopwords("fr"), stopwords("en"),
              c("number_token", "number_token-number_token"),
              c("être", "a", "plus", "peut", "comme", 
              "d’une", "cas", "d’un", 
              "si", "entre", "fait", "non", "doit", 
              "dont", "aussi", 
              "ainsi", "tout", "faire", "donc", 
              "très", "°", "peuvent", "chez", 
              "bien", "où", "toute",
              "autres", "elles", 
              "moins", "in", "après", 
              "encore", "notamment", "certains", 
              "alors", "pourrait", "mise",
              "part", "autre","tous", "possible",
              "exemple", "n’est", "avoir", "souvent","of",">","<","+","u","NA"),
              c("qu’il", "avant", 
              "c’est", "certaines", 
              "selon", "celle", 
              "doivent", "déjà", 
              "celui", "lors", "plusieurs", 
              "sous", "toujours", 
              "depuis", "toutes", "concernant", 
              "devrait", "seulement",
              "faut", "telle",
              "également", "cependant", "façon", "fois",
              "prendre", "point", "nécessaire", 
              "p", "partir", "donner",
              "dès", "ni", "nouvelles",
              "aujourd","hui","agit",
              "objet","place","projet",
              "deux","ment","e"
              )
)
tk <- tokens_remove(tk,toremove)
# DFM format
dfm <- dfm(tk) |>
  dfm_lookup(important_expressions, exclusive = FALSE) |>
  dfm_remove(toremove) |>
  dfm_trim(min_termfreq = 1)

```

## Statistique descriptive

### WordCloud

```{r}
#| eval: true
#| output: true
#| fig-cap: Mots les plus fréquents dans le corpus. La taille est proportionnelle à la fréquence.
#| label: fig-wordcloud
palette <-ggprism::prism_color_pal("winter_bright")(9)
textplot_wordcloud(dfm, min_count = 750, random_order = FALSE, rotation = 0.25,
                   color = palette)
```

### Features similarity

```{r}
tstat_dist <- as.dist(textstat_dist(dfm))
clust <- hclust(tstat_dist)
plot(clust, xlab = "Distance", ylab = NULL)
```


### Evolution de mots choisies

```{r}
#| eval: true
#| output: true
#| fig-cap: Evolution de certains mots au cours du temps
#| label: fig-word_time
#| 
important_words <- c("personne",
                     "nature",
                     "société",
                     "solidarité",
                     "autonomie",
                     "dignité",
                     "liberté",
                     "consentement",
                     "non-commercialisation"
                     )

# word_person <- c("personne",
#                  "personne handicapée mentale",
#                  "personne handicapée",
#                  "enfant",
#                  "parent",
#                  "humain",
#                  "père",
#                  "mère",
#                  "homme",
#                  "femme",
#                  "journaliste",
#                  "médecin",
#                  "personne humain")

tk |>
  tokens_keep(pattern = important_words) |>
  dfm() |>
  textstat_frequency(groups = Annee) |>
ggpubr::ggscatter(x="group", y = "frequency", facet.by = "feature", xlab = "Année",ylab = "Word Frequency")+
    #geom_line()+
    theme_prism()
```
### Contexte without stopwords

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'personne'
#| label: tbl-contexte_personne_bis


kwic(tk, "personne", window=3) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte précédant le mot 'personne'
#| label: tbl-contexte_pre_personne_bis


kwic(tk, "personne", window=2) |> 
  as.data.frame() |> 
  select("pre") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

```{r}
#| eval: true
#| output: true
#| tbl-cap: Examples de contexte suivant le mot 'droit'
#| label: tbl-contexte_droit_bis


kwic(tk, "droit", window=3) |> 
  as.data.frame() |> 
  select("post") |> 
  table() |>
  sort(decreasing = TRUE) |>
  head(10)
```

## On peut complexifier le pre processing

1.  Lemmatization ? pour éviter ce que j'ai déjà fait avec les pluriels ? : meh en français

# LDA

## Find number of topics

```{r}
#| eval: true
recompute_choix_K = FALSE
tm_data <- quanteda::convert(dfm, to = "topicmodels")
stm_data <- convert(dfm, to = "stm")


if(recompute_choix_K){
  list_nb_topics_K <- seq(5, 20)

  tp_nb <- FindTopicsNumber(tm_data, topics = list_nb_topics_K, 
                          metrics = c("Griffiths2004", "CaoJuan2009", 
                                      "Arun2010", "Deveaud2014"),
                          method = "Gibbs")

  diag <- searchK(stm_data$documents, stm_data$vocab, 
                  list_nb_topics_K, 
                  verbose=FALSE)
  save(tp_nb,list_nb_topics_K,diag, file = "../data/report/LDA_report_20231205_metrics.RData")
} else{
  load("../data/report/LDA_report_20231205_metrics.RData")
}

```

### Métriques

```{r}
#| eval: true
#| output: true
#| fig-cap: Evolution des différentes métriques en fonction du nombre de topics
#| fig-subcap: Commenter métriques/résultats
#| label: fig-lda-metrics

FindTopicsNumber_plot(tp_nb)+
  theme_prism()+
  scale_colour_prism("winter_bright")
  
```
### Exclusivité et cohérence sémantique
```{r}
#| eval: true
#| output: true
#| fig-cap: Cohérence sémantique et excluvité en fonction du nombre de topics
#| label: fig-lda-exclu_cohsem
map(diag$results, unlist) |> 
  bind_cols() |> 
  ggplot(aes(exclus, semcoh, label = K)) +
    geom_point() +
    geom_label() +
  theme_prism()
```

```{r}
#| eval: true
num_topic = 8
```

## First model : classic LDA

### implémanté avec topicmodels

```{r}
#| eval: true
#| output: false

tm_data <- quanteda::convert(dfm, to = "topicmodels")

tm_lda <- LDA(tm_data, k = num_topic, method = "Gibbs", 
               control = list(seed = seed))
terms(tm_lda, 10) |> kable()
```

```{r}
#| eval: true
tm_lda_js <- topicmodels2LDAvis(tm_lda, reorder.topics = FALSE) # issu de ldareports
```

```{r}
#| eval: true
#| output: true
#| fig-cap: Top 10 mots par topic, estimation pour 14 topic avec topicmodels
#| label: tbl-lda-tm
report_topics_table(tm_lda)
```

```{r}
serVis(tm_lda_js)
```

## Analyse 1er modèle

### Multidimensional Scaling

```{r}
#| eval: true
RJSONIO::fromJSON(tm_lda_js) -> tm_lda_ldavis
tm_lda_ldavis[["topic.order"]] -> ordre_ldavis
RJSONIO::fromJSON(tm_lda_js)[["mdsDat"]] |> 
  as.data.frame() |>
  rename(order = topics)|>
  mutate(topics = ordre_ldavis[order])-> tm_msd
```

```{r}
#| eval: true
#| echo: true
#| output: true
print("ordre LDAvis")
print(ordre_ldavis)
```

```{r}
#| eval: true
#| output: true
#| fig-cap: Intertopic Distance Map (PCA, multidimensional scaling). Marker size is proportionnal to topic prevalence
#| label: fig-lda-PCA
ggplot(tm_msd, aes(x = x, y = y, label = topics)) +
  geom_point(aes(size = Freq), alpha = 0.6, color = "#00AFBB") +
  geom_label(
    box.padding = 0.3,
    point.padding = 0.1,
    size = 3,
    color = "black",
    nudge_x = -0.02,
    nudge_y = 0.00
  )+
  scale_x_continuous(limits = symmetric_limits) +
  scale_y_continuous(limits = symmetric_limits) +
  geom_quadrant_lines(linetype = "solid") +
  scale_size_area(max_size = 20, limits = c(0, 41), breaks = c(0, 2, 6, 10, 40)) +
  theme_minimal()
```

### Topics by documents

```{r}
#| eval: true

post <- posterior(tm_lda)
post$topics |> 
  as.data.frame() |>
  rename_all(~ paste0("topic ", .)) |>
  tibble::rowid_to_column("ID") |>
  left_join(base_avis_ccne, by="ID") -> tm_metadata
```

```{r}
#| eval: true
#| output: true
#| fig-cap: TOP1 documents where each topics is the more relevant
#| label: tbl-lda-top3doc

ordre_topics <- data.frame(topic = paste("topic", ordre_ldavis), ordre = 1:length(ordre_ldavis))

tm_metadata |>
  pivot_longer(cols = starts_with("topic "), names_to = "topic", values_to = "prevalence") |>
  left_join(ordre_topics, by = "topic")|> 
  group_by(topic) |>
  top_n(1, prevalence) |> 
  ungroup()|>
  arrange(ordre, desc(prevalence)) |>
  select("topic","num_avis","Titre","prevalence","Date","ordre") |>
  rename(Topic = topic, Prevalence = prevalence, "N° Avis"=num_avis) |>
  head(num_topic) |>
  kable(caption = "Most relevant doc by topic")
```

### Graph par années

```{r}
#| eval: true
#| output: true
#| fig-cap: Mean topic prevalence in the corpus by years
#| label: fig-lda-time

name_topic <- list(ordre = paste("topic",ordre_ldavis))
# name_topic <- list(ordre = c(
#                 "éthique",
#                 "fin de vie",
#                 "système de soins",
#                 "données",
#                 "cellule souche",
#                 "science et nature",
#                 "test génétique",
#                 "procréation",
#                 "substance et cognition",
#                 "VIH",
#                 "chirurgie"))

tm_metadata|>
  select(Annee, starts_with("topic")) |>
  pivot_longer(-Annee, names_to = "topic") |>
  left_join(ordre_topics, by = "topic")|> 
  group_by(Annee, topic, ordre) |> 
  summarize(moyenne = mean(value)) |> 
  ggpubr::ggscatter(x="Annee", y = "moyenne", facet.by = "ordre", panel.labs = name_topic, xlab = "Année",ylab = "Mean Prevalence")+
  geom_line()+
  theme_prism()
```

## 2nd model Structural Topic Modelling

```{r}
#| eval: true

stm_data <- convert(dfm, to = "stm")

stm_lda <- stm(dfm,
               K=num_topic, 
               prevalence =~ saisine + s(Annee),
               content =~ theme,
               seed = seed, verbose = FALSE)
```

```{r}
toLDAvis(stm_lda, stm_data$documents,reorder.topics = FALSE)

```

```{r}
#| eval: true
#| output: true
#| fig-cap: Mean STM topic prevalence in the corpus by years
#| label: fig-stm-time

full_stm <- stm_data$meta |> 
  bind_cols(stm_lda$theta |> 
              as_tibble() |> 
              rename_with(~str_replace(.x, "V", "topic "), starts_with("V")))
full_stm |> select(Date, starts_with("topic ")) |>
  pivot_longer(-Date) |> 
  group_by(Date, name) |> 
  summarize(m = mean(value)) |> 
  mutate(topic_number = as.integer(str_extract(name, "\\d+"))) |>
  ggpubr::ggscatter(x="Date", y = "m", 
                    facet.by = "topic_number",
                    xlab = "Date",ylab = "Mean Prevalence")+
  geom_line()+
  theme_prism()
```
```{r}
#| eval: true
#| output: true
#| echo: true
#| fig-cap: STM label words
#| label: fig-stm-label

labelTopics(stm_lda)

```

```{r}
#| eval: true
#| output: true
#| echo: true
#| fig-cap: STM label words
#| label: fig-stm-plot

plot(stm_lda, type = "summary")

```

```{r}
plot(stm_lda, type = "perspectives", topics = c(1,2))
```



```{r}
#| eval: true
#| output: true
#| echo: true
#| fig-cap: STM correlation between topics
#| label: fig-stm-corr_plot


corrmat <- topicCorr(stm_lda)
plot(corrmat)
```
```{r}
#| eval: true
#| output: true
#| echo: true
#| fig-cap: STM correlation matrix between topics
#| label: fig-stm-corr_mat
ggcorrplot(corrmat$cor)
```
rajouter l'impact des métadonnées et leurs impacts

```{r}
findThoughts(stm_lda, texts = base_avis_ccne$avis,meta = base_avis_ccne |> select(-avis), topics = 1:num_topic) -> thoughts

plot(thoughts$index)
```

